# üõ∞Ô∏è Proyecto: An√°lisis de Precios Claros

## üìå Objetivo
An√°lisis exploratorio autodidacta del dataset *Precios Claros - Base SEPA*, con el fin de practicar recolecci√≥n, limpieza, transformaci√≥n y visualizaci√≥n de datos a gran escala, utilizando herramientas como Python y Power BI.

---

## üì¶ Fase 1: Recolecci√≥n de Datos

### üîç Fuente
- **Nombre:** Precios Claros - Base SEPA  
- **Instituci√≥n:** Secretar√≠a de Comercio Interior (Argentina)  
- **Descripci√≥n:** Sistema Electr√≥nico de Publicidad de Precios Argentinos. Re√∫ne informaci√≥n diaria de m√°s de 70.000 productos en grandes comercios del pa√≠s.  
- **Frecuencia:** Diaria  
- **Volumen estimado:** ~12 millones de registros por d√≠a  
- **Licencia:** [Creative Commons Attribution 4.0](https://creativecommons.org/licenses/by/4.0/)  
- **Acceso al dataset:** [Portal de Datos Abiertos](https://datos.produccion.gob.ar/dataset/sepa-precios)

---

## üõ†Ô∏è Fase 2: Manipulaci√≥n y Preparaci√≥n de Datos

### üìÇ Estructura de Archivos Originales
- Los archivos est√°n organizados por d√≠a de la semana.
- Dentro de cada d√≠a, hay una carpeta con la fecha espec√≠fica.
- Cada carpeta contiene entre 85 y 87 archivos `.csv`, organizados por tipo de entidad:
  - `comercios.csv`
  - `sucursales.csv`
  - `productos.csv`
- Cada conjunto pertenece a un comercio distinto, pero repiten nombre, lo cual impide su manipulaci√≥n directa en conjunto.

---

### üßÆ Automatizaci√≥n con Python: Renombrado y Unificaci√≥n

Para facilitar el posterior an√°lisis, se desarroll√≥ un script en Python que copia y renombra todos los archivos agregando prefijos con el d√≠a y la fecha, evitando colisiones por nombres duplicados:

```python
import os
import shutil

origen_base = 'D:/Archivos/1. datasets/Precios Claros - Base SEPA'
destino_base = 'D:/Archivos/1. datasets/Precios Claros - Base SEPA/00_ArchivosRenombradosUnificados'
os.makedirs(destino_base, exist_ok=True)

def copiar_y_renombrar(origen, destino):
    for carpeta_dia in os.listdir(origen):
        ruta_dia = os.path.join(origen, carpeta_dia)
        if os.path.isdir(ruta_dia):
            for carpeta_negocio in os.listdir(ruta_dia):
                ruta_negocio = os.path.join(ruta_dia, carpeta_negocio)
                if os.path.isdir(ruta_negocio):
                    for archivo in os.listdir(ruta_negocio):
                        if archivo.endswith('.csv'):
                            ruta_original = os.path.join(ruta_negocio, archivo)
                            nuevo_nombre = f"{carpeta_dia}_{carpeta_negocio}_{archivo}"
                            ruta_destino = os.path.join(destino, nuevo_nombre)
                            shutil.copy2(ruta_original, ruta_destino)
                            print(f"Copiado: {ruta_original} ‚Üí {ruta_destino}")

copiar_y_renombrar(origen_base, destino_base)
```
### üîÑ Transformaci√≥n en Power BI

Una vez unificados los archivos `.csv` renombrados, se cargan en Power BI para iniciar el proceso de limpieza y transformaci√≥n.

### üóíÔ∏è TABLA COMERCIOS
#### üßπ Tabla consolidada inicial: 
- **Filas:** 658  
- **Columnas:** 9

#### üîß Transformaciones aplicadas:
- Eliminaci√≥n de filas con valores `null` o el string `"null"`.
- Eliminaci√≥n de columnas innecesarias para el an√°lisis:
  - `Source.Name`
  - `comercio_ultima_actualizacion`
  - `comercio_version_sepa`
  - `comercio_bandera_url`
  - `comercio_cuit`
- Normalizaci√≥n de texto:
  - Correcci√≥n de formato de valores en `comercio_razon_social`, `comercio_bandera_nombre`.

#### ‚úÖ Resultado final: 
- **Filas:** 44  
- **Columnas:** 4

### üóíÔ∏è TABLA SUCURSALES
#### üßπ Tabla consolidada inicial: 
- **Filas:** 20619  
- **Columnas:** 22

#### üîß Transformaciones aplicadas:
- Eliminaci√≥n de filas con valores `null` o el string `"null"`.
- Eliminaci√≥n de columnas innecesarias para el an√°lisis:
  - `Source.Name`
  - `sucursales_domingo_horario_atencion`
  - `sucursales_lunes_horario_atencion`
  - `sucursales_martes_horario_atencion`
  - `sucursales_miercoles_horario_atencion` 
  - `sucursales_jueves_horario_atencion`
  - `sucursales_viernes_horario_atencion` 
  - `sucursales_sabado_horario_atencion`
  - `sucursales_nombre`
- Normalizaci√≥n de valores con notaci√≥n cient√≠fica:
  - `sucursal_lat`
  - `sucursal_long`
- Normalizaci√≥n de texto:
  - Correcci√≥n de formato de valores en `sucursales_tipo`, `sucursales_localidad`
- Reemplazo de valores: 
  - `sucursales_provincia`

#### ‚úÖ Resultado final: 
- **Filas:** 20259  
- **Columnas:** 8

### üóíÔ∏è TABLA PRODUCTOS
#### üßπ Datos iniciales: 
- **Filas:** +80 millones 
- **Columnas:** 17

Los archivos csv presentan un peso aproximado de 8GB, no son f√°cilmente tratables, presentan errores en la carga y precisan un tratamiento robusto para obtener buenos resultados.

#### üîß Tratamiento inicial:
- Separaci√≥n manual de archivos por lotes para tratamiento idividual
- Se utiliza Google Colab + Python + Google Drive para identificar y unificar archivos csv con la cantidad de columnas correctas.
```python
# Dar acceso a Drive
from google.colab import drive
drive.mount('/content/drive')

# Importar las bibliotecas necesarias
import pandas as pd
import os

# Definir la ruta de la carpeta en Google Drive que contiene los CSV del lote
ruta_lote = '/content/drive/MyDrive/Productos/1.lote_lunes_01/'
archivos = os.listdir(ruta_lote) # Listar los archivos en la carpeta

# Definir cu√°ntas columnas debe tener un archivo CSV v√°lido
columnas_esperadas = 17

# Crear dos DataFrame vac√≠os
df_unificado = pd.DataFrame() # df para archivos correctos
df_errores = pd.DataFrame() # df para archivos con errores

# Iterar sobre cada archivo .csv en la carpeta
for archivo in archivos:
  if archivo.endswith('.csv'):
    ruta_completa = os.path.join(ruta_lote,archivo) # Obtiene ruta completa al archivo
    try:
      # Se lee el csv forzando que todas las columnas sean tratadas como texto
      df = pd.read_csv(
          ruta_completa,
          encoding='utf-8',
          sep='|',
          low_memory=False,
          dtype=str
          )
      # Se verifica si el archivo tiene la cantidad correcta de columnas
      if df.shape[1] == columnas_esperadas:
        # Si el archivo es correcto se agrega al DataFrame unificado
        df_unificado = pd.concat([df_unificado,df], ignore_index = True)
        print(f'‚úÖ OK: {archivo} ({df.shape[0]} filas)')
      else:
        # Si el archivo tiene errores se agrega al DataFrame de errores
        df['archivo_origen'] = archivo # Se agrega columna para saber de d√≥nde provino
        df_errores = pd.concat([df_errores,df], ignore_index = True)
        print(f'‚ö†Ô∏è ERROR: {archivo} con {df.shape[1]} columnas')

    except Exception as e:
      # Si ocurre un error al leer el archivo, se informa mediante excepci√≥n
            print(f'‚ùå Fallo en archivo {archivo}: {e}')
```
![image](https://github.com/user-attachments/assets/3a9e0fa5-0ae6-48ad-8c51-ce74f24777ee)

```python
# Exportamos el DataFrame con los datos correctos
df_unificado.to_csv('/content/drive/MyDrive/Productos/Limpios/lunes_lote01.csv', index=False, encoding='utf-8')

# Exportamos el DataFrame con los errores de estructura
df_errores.to_csv('/content/drive/MyDrive/Productos/Errores/lunes_lote01.csv', index=False, encoding='utf-8')

# Mensaje final de confirmaci√≥n
print("‚úÖ Archivos guardados: limpio y errores.")
```
‚ö†Ô∏è La estructura de la tabla **Productos** funciona como cat√°logo de los comercios/sucursales. Necesita atomizaci√≥n de datos para facilitar su mantenimiento, escalado y consumo de memoria.

- Se determina la tabla actual como **Cat√°logoComercial** manteniendo las columnas:
  - `id_comercio`
  - `id_bandera	id_sucursal`
  - `id_producto`
  - `productos_precio_lista`
  - `productos_precio_referencia`
  - `productos_cantidad_referencia`
  - `productos_unidad_medida_referencia`
  - `productos_precio_unitario_promo1`
  - `productos_leyenda_promo1`
  - `productos_precio_unitario_promo2`
  - `productos_leyenda_promo2`
- Normalizaci√≥n de texto:
  - Correcci√≥n de formato de valores en `productos_unidad_medida_referencia`.
- Reemplazo de valores: 
  - Los valores de las columnas `productos_precio_referencia`,	`productos_cantidad_referencia`,	`productos_unidad_medida_referencia` ser√°n tratados como *N/A* siempre que no exista un precio de referencia de producto.
 
‚ö†Ô∏è Las columnas: `id_producto`,`productos_descripcion`,`productos_cantidad_presentacion`,	`productos_unidad_medida_presentacion`y `productos_marca` ser√°n parte de la estructura de una nueva **Tabla Productos** utilizando Google Sheets.
